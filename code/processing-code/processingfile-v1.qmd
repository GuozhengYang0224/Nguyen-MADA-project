---
title: "Cleaning Script"
author: "Vincent Nguyen"
date: "2025-02-21"
output: html_document
---

# Setup

Load needed packages. make sure they are installed.

```{r}
# load needed packages
library(here) 
library(dplyr)
library(skimr)
library(ggplot2)
library(zoo)
library(tidyr)
library(lubridate)
library(readxl)
```


# Data loading

```{r}
# importing data

# google data is in three parts
mobility_data_2020 <- read.csv(here("data", "raw-data", "2020_US_Region_Mobility_Report.csv"))
mobility_data_2021 <- read.csv(here("data", "raw-data", "2021_US_Region_Mobility_Report.csv"))
mobility_data_2022 <- read.csv(here("data", "raw-data", "2022_US_Region_Mobility_Report.csv"))
combined_mobility_data <- bind_rows(mobility_data_2020, mobility_data_2021, mobility_data_2022)

# jhk covid time series cases
time_series_covid <- read.csv(here("data", "raw-data", "time_series_covid19_confirmed_US.csv"))

# county health ranking
chr_data_2024 <- read.csv(here("data", "raw-data", "chr_trends_csv_2024.csv"))

# county population information
ch_pop_data <- read_excel(here::here("data", "raw-data", "co-est2023-pop.xlsx"), skip = 3)
```

```{r}
# Remove the second column
ch_pop_data <- ch_pop_data[, -2]

ch_pop_data <- ch_pop_data %>%
  pivot_longer(
    cols = c(`2020`,`2021`, `2022`, `2023`),    # Specify the year columns
    names_to = "year",                    # Create a new column for the years
    values_to = "population_count"              # Create a new column for population counts
  )

# Fix the first column
ch_pop_data <- ch_pop_data %>%
  mutate(
    county = str_remove(`...1`, "^\\."),            
    county = str_remove(county, "County"),     
    county = str_to_lower(county),                  
    state = str_extract(county, "(?<=,).*"),        
    county = str_remove(county, ",.*")              
  ) %>%
  mutate(
    state = str_to_lower(str_trim(state))           
  )

# Change year column to be double for joining later
ch_pop_data$year <- as.double(ch_pop_data$year)


# Clean names to prepare for joining
ch_pop_data <- ch_pop_data %>%
  mutate(
    county = str_trim(str_to_lower(county)),  
    state = str_trim(str_to_lower(state))     
  )

```

After visually inspecting the mobility data, I noticed that many mobility changes were missing. The following code seeks to quantify this.
```{r}

# After visually inspecting the data, I noticed that a lot of mobility changes were missing.
sapply(combined_mobility_data[c("transit_stations_percent_change_from_baseline", 
                         "parks_percent_change_from_baseline", 
                         "retail_and_recreation_percent_change_from_baseline", 
                         "grocery_and_pharmacy_percent_change_from_baseline",
                         "workplaces_percent_change_from_baseline", 
                         "residential_percent_change_from_baseline")], function(x) sum(is.na(x)))



```
# Cleaning and Wrangling

This section looks through the CHR data

```{r}
# First need to filter out the data for what years we are interested in
unique(chr_data_2024$yearspan)

# Based on this, we are most interested in 2020-2022 because of its overlap with the other data.
chr_data_filtered <- filter(chr_data_2024, yearspan %in% c("2020", "2021", "2022"))

# Change yearspan to be a double. This is important for joining all the data frames later.
chr_data_filtered$yearspan <- as.double(chr_data_filtered$yearspan)

# Now we need to decide what meausre interest us the most
unique(chr_data_filtered$measurename)

# We chose uninsured adults as an indicator of access to healthcare (this is listed in the website)
chr_data_filtered <- filter(chr_data_filtered, measurename == "Uninsured adults")


# rename the counties to prep for dataframe joining
chr_data_filtered <- chr_data_filtered %>%
  mutate(
    county = tolower(county),  # Convert 'county' to lowercase
    county = gsub(" county", "", county), # removes the word county
    uninsured_rate = (numerator / denominator) * 100000) # uninsured rate per 100,000


# Check if counties have same names across different staes
duplicates <- chr_data_filtered %>%
  group_by(county, state) %>%
  tally() %>%
  filter(n > 1)

# View the duplicates and looks like there is... need to deal with this if I want to join the data with the other data
print(duplicates)

# Change abbreviated state names into the full name so I can join them easier

# Create a mapping for state abbreviations to full names and convert the full names to lowercase
state_mapping <- data.frame(
  state_abbr = c("AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DE", "FL", "GA", "HI", "ID", "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD", "MA", "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NH", "NJ", "NM", "NY", "NC", "ND", "OH", "OK", "OR", "PA", "RI", "SC", "SD", "TN", "TX", "UT", "VT", "VA", "WA", "WV", "WI", "WY"),
  state_full = tolower(c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"))
)

# Convert state abbreviation to full name in chr_data_2024
chr_data_filtered <- chr_data_filtered %>%
  left_join(state_mapping, by = c("state" = "state_abbr"))



```

By inspecting the data, some problems become apparent. AS mentioned above, the Mobility Report is missing a tremendous amount of values. The Time Series data and Mobility Report are structured in entirely different ways. Joining the two will be difficult without mutating one. I chose to change the Time Series data. 

Next, we also can see that the naming scheme of the columns differ so we need to standardize that as well.

Lastly, both datasets do not have the same range in dates


```{r}

# Pivot the time series data and change names around
cases_long <- time_series_covid %>%
  pivot_longer(
    cols = starts_with("X"),  
    names_to = "date",
    values_to = "total_cases"
  ) %>%
  mutate(date = gsub("^X", "", date),  # Remove leading x for dates to join data sets in a bit
         date = gsub("\\.", "/", date),  # Replace dots with slashes
         date = as.Date(date, format = "%m/%d/%y"))  # Use "%y" instead of "%Y"

# Standardize county & state names (convert to lowercase to avoid mismatches)
cases_long <- cases_long %>%
  rename(county = Admin2, state = Province_State) %>%
  mutate(county = tolower(county), state = tolower(state))

mobility_df <- combined_mobility_data %>%
  rename(county = sub_region_2, state = sub_region_1) %>%
  mutate(county = tolower(county), 
         state = tolower(state),
         county = gsub(" county$", "", county),  # Remove "county" from county name
         date = as.Date(date, format = "%Y-%m-%d"))  # Correct format for "YYYY-MM-DD"


# Filter cases_long and mobility_df based on the date range
cases_long_filtered <- cases_long %>%
  filter(date >= "2020-02-15" & date <= "2022-10-15")

mobility_df_filtered <- mobility_df %>%
  filter(date >= "2020-02-15" & date <= "2022-10-15")

# Merge the data sets together
merged_df <- cases_long_filtered %>%
  inner_join(mobility_df_filtered, by = c("county", "state", "date"))

# Finally, remove any rows missing mobility changes to ensure consistency. We also have a lot of data values so I deemed it permissible.
merged_df_clean <- merged_df %>%
  drop_na(c(transit_stations_percent_change_from_baseline, parks_percent_change_from_baseline, retail_and_recreation_percent_change_from_baseline, grocery_and_pharmacy_percent_change_from_baseline,workplaces_percent_change_from_baseline, residential_percent_change_from_baseline))

# Additionally, add a column about new cases for further analysis down the line.
merged_df_clean <- merged_df_clean %>%
  arrange(state, county, date) %>%  # Sort (Need to make sure calculations occur between the correct states/counties and in order)
  group_by(state, county) %>%  # Group by state and county to calculate new cases within each county
  mutate(new_cases = c(NA, diff(total_cases))) %>%  # Calculate new cases
  ungroup()  # Ungroup after the calculation

# Create column for mean average mobiltiy change for that given day and location. I omitted mobility changes to residencies because that may be more of an indication of who is at home.
merged_df_clean <- merged_df_clean %>%
  arrange(state, county, date) %>%  # Sort to ensure correct calculations
  group_by(state, county) %>%  # Group by state and county
  mutate(average_mobility = rowMeans(
    cbind(transit_stations_percent_change_from_baseline, 
          parks_percent_change_from_baseline, 
          retail_and_recreation_percent_change_from_baseline, 
          grocery_and_pharmacy_percent_change_from_baseline, 
          workplaces_percent_change_from_baseline), 
    na.rm = TRUE)) %>%
  ungroup()

merged_df_clean <- merged_df_clean %>%
  mutate(year = year(date)) %>%
  left_join(chr_data_filtered %>% select(state_full, county, uninsured_rate, yearspan), 
            by = c("state" = "state_full", "county" = "county", "year" = "yearspan"))

merged_df_clean <- merged_df_clean %>%
  left_join(
    ch_pop_data %>% 
      select(year, population_count, county, state),
    by = c("state" = "state", "county" = "county", "year" = "year")
  )
```

All done, data is clean now. 

Let's assign at the end to some final variable, this makes it easier to add further cleaning steps above.

```{r}
processeddata <- merged_df_clean
```


# Save data 

```{r}
save_data_location <- here::here("data","processed-data","processeddata.rds")
saveRDS(processeddata, file = save_data_location)
```

